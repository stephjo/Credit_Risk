{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss,auc,precision_score, recall_score, f1_score, roc_auc_score, accuracy_score,precision_recall_curve, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,cross_val_score,cross_validate\n",
    "from sklearn.preprocessing import RobustScaler,PowerTransformer\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "# import xgboost\n",
    "# from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "bold='\\033[1m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= \"https://s3.amazonaws.com/datarobot_public_datasets/DR_Demo_Lending_Club.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(PATH, low_memory=False,parse_dates=['earliest_cr_line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_raw, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_data(df):   \n",
    "\n",
    "    # Make a backup copy\n",
    "    df_cpu_cpy = df.copy()\n",
    "    \n",
    "    #Columns available in dataset\n",
    "    print(bold+\"\\nAttributes of the dataset\\n\", df.columns.values)\n",
    "    \n",
    "    #Dimensions of the dataset\n",
    "    print(bold+\"\\nNo of rows:\", df.shape[0])\n",
    "    print(bold+\"No of columns:\", df.shape[1])\n",
    "    \n",
    "    #View the datatypes\n",
    "    df.info()\n",
    "    \n",
    "    #Check for missing values\n",
    "    print(bold+\"\\nMissing values in the dataset:\",df.isnull().sum().max())\n",
    "    print(bold+\"\\nMissing values in the dataset:\",df.columns[df.isnull().any()].tolist())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stat(df):\n",
    "    \n",
    "    print(\"--\"*40)    \n",
    "    print(bold+\"Summary Statistics of numeric features:\" )\n",
    "    print(\"--\"*40)\n",
    "    print(df.describe())\n",
    "    print(\"--\"*40)\n",
    "    print(bold+\"Summary Statistics of categorical features:\")\n",
    "    print(\"--\"*40)\n",
    "#     print(df.describe(include=['O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, \n",
    "                                     infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "   \n",
    "#     for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', \n",
    "#             'Dayofyear', 'Is_month_end', 'Is_month_start', \n",
    "#             'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', \n",
    "#             'Is_year_start'):    \n",
    "    df[targ_pre+'Year'] = getattr(fld.dt,'year')\n",
    "    \n",
    "#     df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df,col,name):\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum():\n",
    "            df[name+'_na']=np.isnan(df[name]) * 1\n",
    "            df[name] = col.fillna(col.median()) \n",
    "    else:\n",
    "        df[name] =col.fillna(col.mode().iloc[0])   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cat_levels(df,col,name,max_cat_num):\n",
    "    df_len=len(df)\n",
    "    val_list=col.value_counts().nlargest(max_cat_num).index\n",
    "    df[name] = col.where(col.isin(val_list), 'others')\n",
    "\n",
    "    return df        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_cat_cols(df):\n",
    "    numerics = ['float64', 'int64']\n",
    "    num_ds =df.select_dtypes(include=numerics)  \n",
    "    cat_ds =df.select_dtypes(exclude=numerics)\n",
    "    num_cols=num_ds.keys().tolist()\n",
    "    cat_cols=cat_ds.keys().tolist()\n",
    "    return num_cols,cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cat_features(df,n,c,max_cat_num):\n",
    "#     cat_cols=num_cat_cols(df,isnum=False)\n",
    "    if is_string_dtype(c):\n",
    "        if c.nunique()>max_cat_num :df=fix_cat_levels(df,c,n,max_cat_num)    \n",
    "    return df\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df,col,isVector=None):\n",
    "        df[col]=df[col].fillna('na')\n",
    "        if isVector:\n",
    "            vectoriser = TfidfVectorizer()\n",
    "            features = vectoriser.fit_transform(df) \n",
    "        else:\n",
    "            df[col]=df[col].apply(len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(df):\n",
    "    num_cols,cat_cols=num_cat_cols(df)\n",
    "    std = RobustScaler()\n",
    "    x = df[num_cols].values\n",
    "    x_scaled = std.fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=num_cols, index = df.index)\n",
    "    df[num_cols] = df_temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df,y_fld,drop_flds=None,do_scale=None,max_cat_num=None,text_flds=None):\n",
    "    '''\n",
    "\n",
    "     :param df: train/test\n",
    "     :param y_fld: 'is_bad'\n",
    "     :param drop_flds: 'id'\n",
    "     :param do_scale: None\n",
    "     :param max_cat_num: 10\n",
    "     :param text_flds: 'Notes,Purpose'\n",
    "     :return: [df,labels]\n",
    "    '''\n",
    "\n",
    "    if not drop_flds:\n",
    "        drop_flds=[]\n",
    "    df=df.copy()\n",
    "    y=df[y_fld].values\n",
    "    df.drop(drop_flds+[y_fld],axis=1,inplace=True)\n",
    "    for n,c in df.items():fill_missing(df,c,n)\n",
    "    for col in text_flds:\n",
    "        if col in df.columns:vectorize(df,col)\n",
    "    df=normalise(df)\n",
    "    for n,c in df.items():transform_cat_features(df,n,c,max_cat_num)\n",
    "    res=[pd.get_dummies(df,drop_first=True),y]  \n",
    "    return res\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_testdataset(train_cols,test):\n",
    "    missing_cols = set(train_cols ) - set( test.columns )\n",
    "    # Add a missing column in test set with default value equal to 0\n",
    "    for c in missing_cols:\n",
    "        test[c] = 0\n",
    "    # Ensure the order of column in the test set is in the same order than in train set\n",
    "    test = test[train_cols]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_data(df):\n",
    "    '''\n",
    "    -Extract year from the 'earliest_cr_line' date\n",
    "    -Perform the preprocessing on the data\n",
    "      -Drop id column and target column from the train/test data\n",
    "      -Fill missing values of numeric columns with median and categorical columns with mode\n",
    "      -Normalise numeric columns using robustscalar\n",
    "      -Transformed categorical columns with levels > 10\n",
    "      -Converted text columns to numeric columns by replacing with length of text\n",
    "      -dummy encoding on categorical columns\n",
    "\n",
    "    :param df: source df_train /df_test\n",
    "    :return: df_train/df_test,train_labels,test_labels\n",
    "    '''\n",
    "    add_datepart(df, 'earliest_cr_line')\n",
    "    df, labels = process_df(df, 'is_bad', drop_flds=['Id'], max_cat_num=10, text_flds=['Notes', 'purpose'])\n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df, labels):\n",
    "    '''\n",
    "    Oversample data using SMOTE to handle the imbalanced data\n",
    "    :param df: source:df_train/df_test\n",
    "    :param labels: train_labels/test_labels\n",
    "    :return: x_sampled, y_sampled\n",
    "    '''\n",
    "    sampler = SMOTE()\n",
    "    x_sampled, y_sampled = sampler.fit_sample(df, labels)\n",
    "    return x_sampled, y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate(model, df, labels):\n",
    "    '''\n",
    "    Crossvalidate train data using StratifiedKFold with 5 splits\n",
    "\n",
    "    :param model: log_model/gbt_model\n",
    "    :param df: train/test\n",
    "    :param labels: train_labels/test_labels\n",
    "    :return:\n",
    "    '''\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scoring = ['neg_log_loss', 'f1']\n",
    "\n",
    "    scores = cross_validate(model, df, labels, cv=skf, scoring=scoring)\n",
    "    print('Log loss score# (1) mean: {} (2)variance: {}'.format(-np.mean(scores['test_neg_log_loss']),\n",
    "                                                                np.var(scores['test_neg_log_loss'])))\n",
    "    print('F1 score# (1) mean: {} (2)variance: {}'.format(np.mean(scores['test_f1']), np.var(scores['test_f1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, df, labels):\n",
    "    '''\n",
    "    Crossvalidate and fit the model on training data\n",
    "    :param model: log_model/gbt_model\n",
    "    :param df: train/test\n",
    "    :param labels: train_labels/test_labels\n",
    "    :return:\n",
    "    '''\n",
    "    crossvalidate(model, df, labels)\n",
    "    model.fit(df, labels)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, df, labels):\n",
    "    '''\n",
    "    Make predictions using trained models on test data\n",
    "    Calculate logloss and f1 score for each model\n",
    "    :param model: log_model/gbt_model\n",
    "    :param df: train/test\n",
    "    :param labels: train_labels/test_labels\n",
    "    :return:\n",
    "    '''\n",
    "    predictions = model.predict(df)\n",
    "    f1 = f1_score(predictions, labels)\n",
    "    pred_probs = model.predict_proba(df)\n",
    "    logloss = log_loss(labels, pred_probs, eps=1e-15)\n",
    "    print('Prediction Log loss score# : %.2f' % (logloss))\n",
    "    print(\"Prediction F1 score # : %.2f \" % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df,df_test):\n",
    "    \n",
    "      \n",
    "    '''\n",
    "    -Preprocess and resample train data\n",
    "    -Crossvalidate the '12 regularised logistic regression' and  'GradientBoostingClassifier' models using stratified 5 folds\n",
    "    -Calculate logloss and f1 score for the models on train data predictions\n",
    "    -Preprocess and resample test data\n",
    "    -Predict the labels of test data using trained models\n",
    "    -Calculate logloss and f1 score for the predictions\n",
    "    :param df: Train dataset\n",
    "    :param df_test: Test dataset\n",
    "    '''\n",
    "\n",
    "    log_model = LogisticRegression(class_weight='balanced', penalty='l2', random_state=42)\n",
    "    gbt_model = GradientBoostingClassifier(max_features='sqrt',\n",
    "                                           n_estimators=100,\n",
    "                                           learning_rate=0.02,\n",
    "                                           max_depth=10,\n",
    "                                           subsample=0.8)\n",
    "    print('Preprocessing training data:')\n",
    "    df_train, train_labels = Prepare_data(df)\n",
    "    df_train_re, train_labels_re = resample_data(df_train, train_labels)\n",
    "\n",
    "    print('Preprocessing testing data:')\n",
    "    df_test, test_labels = Prepare_data(df_test)\n",
    "    df_test = align_testdataset(df_train.columns, df_test)\n",
    "    df_test_re, test_labels_re = resample_data(df_test, test_labels)\n",
    "\n",
    "    # Logistic regression\n",
    "    print('Training Logistic regression model...')\n",
    "    print('Logistic regression cross validation scores:')\n",
    "    print(\"--\" * 40)\n",
    "    log_model = train_model(log_model, df_train_re, train_labels_re)\n",
    "\n",
    "    print('Testing Logistic regression model...')\n",
    "    print('Logistic regression test scores:')\n",
    "    print(\"--\" * 40)\n",
    "    test_model(log_model, df_test_re, test_labels_re)\n",
    "\n",
    "\n",
    "    # GradientBoosting Classifier\n",
    "    print('Training GradientBoosting Classifier model model...')\n",
    "    print('GradientBoosting Classifier cross validation scores:')\n",
    "    print(\"--\" * 40)\n",
    "    gbt_model=train_model(gbt_model,df_train_re,train_labels_re)\n",
    "    print('Testing GradientBoosting Classifier model...')\n",
    "    print('GradientBoosting Classifier test scores:')\n",
    "    print(\"--\" * 40)\n",
    "    test_model(gbt_model,df_test_re,test_labels_re)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data:\n",
      "Preprocessing testing data:\n",
      "Training Logistic regression model...\n",
      "Logistic regression cross validation scores:\n",
      "--------------------------------------------------------------------------------\n",
      "Log loss score# (1) mean: 0.6068071797292562 (2)variance: 7.934491249527645e-05\n",
      "F1 score# (1) mean: 0.6656572847416996 (2)variance: 4.531882457848716e-05\n",
      "Testing Logistic regression model...\n",
      "Logistic regression test scores:\n",
      "--------------------------------------------------------------------------------\n",
      "Prediction Log loss score# : 0.63\n",
      "Prediction F1 score # : 0.64 \n",
      "Training GradientBoosting Classifier model model...\n",
      "GradientBoosting Classifier cross validation scores:\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_test(df_train,df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
